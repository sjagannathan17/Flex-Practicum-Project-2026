#!/usr/bin/env python3
"""
RAG ç³»ç»Ÿè¯Šæ–­å·¥å…·
ç”¨äºå®šä½é—®é¢˜å‡ºåœ¨å“ªä¸ªç¯èŠ‚ï¼šPDFè§£æ / åˆ†å— / æ£€ç´¢ / ç”Ÿæˆ

ä½¿ç”¨æ–¹æ³•ï¼š
    cd Flex-Practicum-Project-2026
    python scripts/diagnose_rag.py
"""

import sys
from pathlib import Path

# Add project root to path
sys.path.insert(0, str(Path(__file__).parent.parent))

from backend.core.database import get_collection, embed_text


# ===========================================================================
# 1. PDF è§£æè´¨é‡æ£€æµ‹
# ===========================================================================
def diagnose_pdf_parsing():
    """æ£€æŸ¥ PDF è§£ææ˜¯å¦æ­£ç¡®æå–äº†å…³é”®è´¢åŠ¡æ•°æ®"""
    print("\n" + "=" * 70)
    print("  1. PDF è§£æè´¨é‡è¯Šæ–­")
    print("=" * 70)
    
    collection = get_collection()
    if collection.count() == 0:
        print("  âŒ ChromaDB ä¸ºç©ºï¼Œè¯·å…ˆè¿è¡Œ build_chromadb.py")
        return False
    
    # æœç´¢åº”è¯¥å­˜åœ¨çš„å…³é”®å†…å®¹
    test_queries = [
        # CapEx ç›¸å…³ï¼ˆå¿…é¡»èƒ½æ‰¾åˆ°ï¼‰
        ("CapEx æ•°æ®", "purchases of property and equipment capital expenditure"),
        ("ç°é‡‘æµé‡è¡¨", "consolidated statements of cash flows investing activities"),
        ("èµ„äº§è´Ÿå€ºè¡¨", "total assets total liabilities balance sheet"),
        
        # å…¬å¸ç‰¹å®š
        ("Flex æ•°æ®", "Flex Ltd revenue operating income"),
        ("Jabil æ•°æ®", "Jabil Inc capital expenditure property equipment"),
    ]
    
    issues = []
    for label, query in test_queries:
        query_emb = embed_text(query)
        results = collection.query(
            query_embeddings=[query_emb],
            n_results=3,
            include=["documents", "metadatas", "distances"]
        )
        
        if not results["documents"][0]:
            issues.append(f"âŒ {label}: æœªæ‰¾åˆ°ä»»ä½•ç»“æœ")
            continue
        
        best_sim = 1 - results["distances"][0][0]
        best_doc = results["documents"][0][0][:200]
        best_meta = results["metadatas"][0][0]
        
        status = "âœ…" if best_sim > 0.3 else "âš ï¸"
        print(f"\n  {status} {label}")
        print(f"     ç›¸ä¼¼åº¦: {best_sim:.3f}")
        print(f"     æ¥æº: [{best_meta.get('company', '?')}] {best_meta.get('source_file', '?')}")
        print(f"     å†…å®¹: {best_doc}...")
        
        if best_sim < 0.3:
            issues.append(f"âš ï¸ {label}: ç›¸ä¼¼åº¦è¿‡ä½ ({best_sim:.3f})")
    
    if issues:
        print(f"\n  å‘ç° {len(issues)} ä¸ªæ½œåœ¨é—®é¢˜:")
        for issue in issues:
            print(f"    {issue}")
        return False
    
    print("\n  âœ… PDF è§£æè´¨é‡è‰¯å¥½")
    return True


# ===========================================================================
# 2. è¡¨æ ¼æå–è´¨é‡æ£€æµ‹
# ===========================================================================
def diagnose_table_extraction():
    """æ£€æŸ¥è¡¨æ ¼æ˜¯å¦è¢«æ­£ç¡®æå–å’Œåºåˆ—åŒ–"""
    print("\n" + "=" * 70)
    print("  2. è¡¨æ ¼æå–è´¨é‡è¯Šæ–­")
    print("=" * 70)
    
    collection = get_collection()
    
    # æ£€æŸ¥æ˜¯å¦æœ‰è¡¨æ ¼ç±»å‹çš„ chunk
    results = collection.get(
        where={"chunk_type": "table"},
        include=["documents", "metadatas"],
        limit=5,
    )
    
    if not results["documents"]:
        print("  âš ï¸ æœªæ‰¾åˆ°è¡¨æ ¼ç±»å‹çš„ chunk")
        print("     å¯èƒ½åŸå› : è¡¨æ ¼æœªè¢«è¯†åˆ«ï¼Œæˆ–ä½¿ç”¨äº†æ—§ç‰ˆåˆ†å—")
        
        # å°è¯•æœç´¢è¡¨æ ¼å†…å®¹
        query_emb = embed_text("consolidated statements cash flows capex property equipment")
        search_results = collection.query(
            query_embeddings=[query_emb],
            n_results=5,
            include=["documents", "metadatas"]
        )
        
        print("\n  å°è¯•æœç´¢è¡¨æ ¼å†…å®¹:")
        for doc, meta in zip(search_results["documents"][0], search_results["metadatas"][0]):
            has_table = "|" in doc or "---" in doc
            status = "ğŸ“Š" if has_table else "ğŸ“„"
            print(f"    {status} [{meta.get('company')}] {meta.get('chunk_type', 'unknown')}")
            if has_table:
                # æ˜¾ç¤ºè¡¨æ ¼ç‰‡æ®µ
                lines = [l for l in doc.split("\n") if "|" in l][:3]
                for line in lines:
                    print(f"       {line[:80]}")
        return False
    
    print(f"  âœ… æ‰¾åˆ° {len(results['documents'])} ä¸ªè¡¨æ ¼ chunk")
    
    for i, (doc, meta) in enumerate(zip(results["documents"][:3], results["metadatas"][:3])):
        print(f"\n  è¡¨æ ¼ {i+1}: [{meta.get('company')}] {meta.get('table_type', 'unknown')}")
        print(f"     ä¸Šä¸‹æ–‡: {meta.get('table_context', '')[:50]}")
        # æ˜¾ç¤ºè¡¨æ ¼å‰å‡ è¡Œ
        lines = doc.split("\n")[:5]
        for line in lines:
            print(f"     {line[:70]}")
    
    return True


# ===========================================================================
# 3. çˆ¶å­æ–‡æ¡£ç»“æ„æ£€æµ‹
# ===========================================================================
def diagnose_parent_child():
    """æ£€æŸ¥çˆ¶å­æ–‡æ¡£ç»“æ„æ˜¯å¦æ­£ç¡®"""
    print("\n" + "=" * 70)
    print("  3. çˆ¶å­æ–‡æ¡£ç»“æ„è¯Šæ–­")
    print("=" * 70)
    
    collection = get_collection()
    
    # ç»Ÿè®¡å„ç±»å‹ chunk
    chunk_types = {"child": 0, "parent": 0, "table": 0, "legacy": 0, "unknown": 0}
    
    # è·å–æ‰€æœ‰ chunk çš„å…ƒæ•°æ®
    all_results = collection.get(
        include=["metadatas"],
        limit=10000,
    )
    
    for meta in all_results["metadatas"]:
        ctype = meta.get("chunk_type", "unknown")
        if ctype in chunk_types:
            chunk_types[ctype] += 1
        else:
            chunk_types["unknown"] += 1
    
    print(f"\n  Chunk ç±»å‹åˆ†å¸ƒ:")
    for ctype, count in chunk_types.items():
        if count > 0:
            print(f"    {ctype:<10}: {count:>5}")
    
    # æ£€æŸ¥æ˜¯å¦ä½¿ç”¨äº†æ–°çš„çˆ¶å­ç»“æ„
    if chunk_types["child"] == 0 and chunk_types["parent"] == 0:
        print("\n  âš ï¸ æœªä½¿ç”¨çˆ¶å­æ–‡æ¡£ç»“æ„")
        print("     å»ºè®®: é‡æ–°è¿è¡Œ build_chromadb.py ä½¿ç”¨å¢å¼ºç‰ˆåˆ†å—")
        return False
    
    # éªŒè¯çˆ¶å­å…³ç³»
    child_results = collection.get(
        where={"chunk_type": "child"},
        include=["metadatas"],
        limit=10,
    )
    
    valid_refs = 0
    for meta in child_results["metadatas"]:
        if meta.get("parent_id") and meta.get("parent_preview"):
            valid_refs += 1
    
    if valid_refs == len(child_results["metadatas"]):
        print(f"\n  âœ… çˆ¶å­å…³ç³»éªŒè¯é€šè¿‡ ({valid_refs}/{len(child_results['metadatas'])})")
        return True
    else:
        print(f"\n  âš ï¸ éƒ¨åˆ† child ç¼ºå°‘ parent å¼•ç”¨ ({valid_refs}/{len(child_results['metadatas'])})")
        return False


# ===========================================================================
# 4. æ£€ç´¢è´¨é‡æ£€æµ‹
# ===========================================================================
def diagnose_retrieval():
    """æµ‹è¯•æ£€ç´¢æ˜¯å¦èƒ½æ‰¾åˆ°æ­£ç¡®ç­”æ¡ˆ"""
    print("\n" + "=" * 70)
    print("  4. æ£€ç´¢è´¨é‡è¯Šæ–­")
    print("=" * 70)
    
    # æµ‹è¯•é—®é¢˜ - è¿™äº›åº”è¯¥èƒ½åœ¨æ–‡æ¡£ä¸­æ‰¾åˆ°ç­”æ¡ˆ
    test_cases = [
        {
            "query": "What was Flex's capital expenditure in fiscal year 2024?",
            "expected_keywords": ["flex", "capital", "expenditure", "property", "equipment"],
            "expected_company": "Flex",
        },
        {
            "query": "Compare Jabil and Celestica revenue",
            "expected_keywords": ["revenue", "net sales"],
            "expected_company": None,  # Should find multiple companies
        },
        {
            "query": "What are Sanmina's manufacturing facilities?",
            "expected_keywords": ["sanmina", "facility", "plant", "manufacturing"],
            "expected_company": "Sanmina",
        },
    ]
    
    from backend.rag.retriever import search_documents
    
    issues = []
    for case in test_cases:
        print(f"\n  æŸ¥è¯¢: {case['query'][:50]}...")
        
        # æš‚æ—¶ç¦ç”¨ reranking ä»¥æµ‹è¯•åŸå§‹æ£€ç´¢
        docs = search_documents(case["query"], n_results=5, use_reranking=False)
        
        if not docs:
            issues.append(f"âŒ æœªæ‰¾åˆ°ä»»ä½•ç»“æœ: {case['query'][:30]}...")
            continue
        
        # æ£€æŸ¥ç»“æœè´¨é‡
        top_doc = docs[0]
        content_lower = top_doc["content"].lower()
        
        found_keywords = sum(1 for kw in case["expected_keywords"] if kw in content_lower)
        keyword_ratio = found_keywords / len(case["expected_keywords"])
        
        company_match = True
        if case["expected_company"]:
            company_match = top_doc["company"] == case["expected_company"]
        
        status = "âœ…" if keyword_ratio > 0.3 and company_match else "âš ï¸"
        print(f"    {status} Top ç»“æœ: [{top_doc['company']}] {top_doc['source']}")
        print(f"       ç›¸ä¼¼åº¦: {top_doc['similarity']:.3f}")
        print(f"       å…³é”®è¯åŒ¹é…: {found_keywords}/{len(case['expected_keywords'])}")
        
        if keyword_ratio < 0.3:
            issues.append(f"âš ï¸ å…³é”®è¯åŒ¹é…ç‡ä½: {case['query'][:30]}...")
        if not company_match:
            issues.append(f"âš ï¸ å…¬å¸ä¸åŒ¹é…: æœŸæœ› {case['expected_company']}, å¾—åˆ° {top_doc['company']}")
    
    if issues:
        print(f"\n  å‘ç° {len(issues)} ä¸ªæ£€ç´¢é—®é¢˜:")
        for issue in issues:
            print(f"    {issue}")
        return False
    
    print("\n  âœ… æ£€ç´¢è´¨é‡è‰¯å¥½")
    return True


# ===========================================================================
# 5. ç«¯åˆ°ç«¯æµ‹è¯•
# ===========================================================================
def diagnose_end_to_end():
    """å®Œæ•´çš„é—®ç­”æµ‹è¯•"""
    print("\n" + "=" * 70)
    print("  5. ç«¯åˆ°ç«¯é—®ç­”æµ‹è¯•")
    print("=" * 70)
    
    try:
        from backend.rag.pipeline import process_query_sync
    except ImportError as e:
        print(f"  âŒ æ— æ³•å¯¼å…¥ pipeline: {e}")
        return False
    
    test_query = "What was Flex's capital expenditure in the most recent fiscal year?"
    
    print(f"\n  æµ‹è¯•é—®é¢˜: {test_query}")
    print("  æ­£åœ¨å¤„ç†...")
    
    try:
        result = process_query_sync(
            query=test_query,
            mode="rag",
            use_reranking=False,  # å…ˆæµ‹è¯•æ—  reranking
        )
        
        print(f"\n  å“åº”é•¿åº¦: {len(result.get('response', ''))} å­—ç¬¦")
        print(f"  æ£€ç´¢åˆ°çš„æº: {len(result.get('sources', []))} ä¸ª")
        
        response = result.get("response", "")
        
        # æ£€æŸ¥å“åº”è´¨é‡
        has_number = any(c.isdigit() for c in response)
        has_capex = "capex" in response.lower() or "capital" in response.lower()
        has_flex = "flex" in response.lower()
        
        if has_number and has_capex and has_flex:
            print("  âœ… å“åº”åŒ…å«å…³é”®ä¿¡æ¯ (æ•°å­— + CapEx + Flex)")
            print(f"\n  å“åº”é¢„è§ˆ:\n  {response[:500]}...")
            return True
        else:
            print("  âš ï¸ å“åº”å¯èƒ½ä¸å®Œæ•´")
            print(f"    - åŒ…å«æ•°å­—: {has_number}")
            print(f"    - åŒ…å« CapEx: {has_capex}")
            print(f"    - åŒ…å« Flex: {has_flex}")
            print(f"\n  å“åº”é¢„è§ˆ:\n  {response[:500]}...")
            return False
            
    except Exception as e:
        print(f"  âŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False


# ===========================================================================
# ä¸»è¯Šæ–­å‡½æ•°
# ===========================================================================
def run_diagnostics():
    """è¿è¡Œæ‰€æœ‰è¯Šæ–­"""
    print("\n" + "=" * 70)
    print("  RAG ç³»ç»Ÿè¯Šæ–­å·¥å…·")
    print("  ç”¨äºå®šä½é—®é¢˜å‡ºåœ¨å“ªä¸ªç¯èŠ‚")
    print("=" * 70)
    
    results = {}
    
    # 1. PDF è§£æ
    results["pdf_parsing"] = diagnose_pdf_parsing()
    
    # 2. è¡¨æ ¼æå–
    results["table_extraction"] = diagnose_table_extraction()
    
    # 3. çˆ¶å­ç»“æ„
    results["parent_child"] = diagnose_parent_child()
    
    # 4. æ£€ç´¢è´¨é‡
    results["retrieval"] = diagnose_retrieval()
    
    # 5. ç«¯åˆ°ç«¯
    results["end_to_end"] = diagnose_end_to_end()
    
    # æ€»ç»“
    print("\n" + "=" * 70)
    print("  è¯Šæ–­æ€»ç»“")
    print("=" * 70)
    
    all_pass = True
    for name, passed in results.items():
        status = "âœ… é€šè¿‡" if passed else "âŒ éœ€å…³æ³¨"
        print(f"  {name:<20}: {status}")
        if not passed:
            all_pass = False
    
    print("\n" + "-" * 70)
    if all_pass:
        print("  ğŸ‰ æ‰€æœ‰æ£€æµ‹é€šè¿‡ï¼RAG ç³»ç»Ÿè¿è¡Œæ­£å¸¸ã€‚")
    else:
        print("  âš ï¸  éƒ¨åˆ†æ£€æµ‹æœªé€šè¿‡ï¼Œè¯·æ ¹æ®ä¸Šè¿°ä¿¡æ¯å®šä½é—®é¢˜ï¼š")
        print()
        print("  é—®é¢˜å®šä½æŒ‡å—:")
        print("  - pdf_parsing å¤±è´¥     â†’ PDF è§£ææœ‰é—®é¢˜ï¼Œè€ƒè™‘ä½¿ç”¨ Docling/MinerU")
        print("  - table_extraction å¤±è´¥ â†’ è¡¨æ ¼æœªæ­£ç¡®æå–ï¼Œæ£€æŸ¥ serialize_table_enhanced")
        print("  - parent_child å¤±è´¥    â†’ éœ€è¦é‡æ–°è¿è¡Œ build_chromadb.py")
        print("  - retrieval å¤±è´¥       â†’ æ£€ç´¢é…ç½®æœ‰é—®é¢˜ï¼ŒæŸ¥çœ‹ retriever.py")
        print("  - end_to_end å¤±è´¥      â†’ LLM ç”Ÿæˆæœ‰é—®é¢˜ï¼Œæ£€æŸ¥ API key å’Œ prompt")
    
    print("=" * 70)
    return all_pass


if __name__ == "__main__":
    run_diagnostics()
